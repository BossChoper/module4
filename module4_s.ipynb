{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a6b145",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "from sklearn.decomposition import PCA\n",
    "#visualization\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c5911b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "df = pd.read_csv('Coffee Chain.csv')\n",
    "\n",
    "#display basic information\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b008637b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data exploration\n",
    "print(\"Data Types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\nBasic Statistics:\")\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fb9d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean column names, remove extra quotes\n",
    "for col in df.columns:\n",
    "    df[col] = df[col].apply(lambda x: x.strip('\"\"\"') if isinstance(x, str) else x)\n",
    "\n",
    "#convert Date to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "#check unique values for categorical variables\n",
    "print(\"Market Types:\", df['Market'].unique())\n",
    "print(\"\\nMarket Sizes:\", df['Market Size'].unique())\n",
    "print(\"\\nProduct Lines:\", df['Product Line'].unique())\n",
    "print(\"\\nProduct Types:\", df['Product Type'].unique())\n",
    "print(\"\\nCaffeine Types:\", df['Type'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c98d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select features for clustering\n",
    "features_for_clustering = ['Sales', 'Profit', 'Margin', 'Marketing', 'Inventory', \n",
    "                          'Difference Between Actual and Target Profit']\n",
    "\n",
    "#create feature matrix\n",
    "X = df[features_for_clustering].copy()\n",
    "\n",
    "#display feature statistics\n",
    "print(\"Feature Statistics:\")\n",
    "print(X.describe())\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"\\nFeature Correlations:\")\n",
    "correlation_matrix = X.corr()\n",
    "print(correlation_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20eeaa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize feature correlations\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Feature Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e1de3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "#convert back to DataFrame for easier handling\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=features_for_clustering)\n",
    "\n",
    "print(\"Standardized Features - First 10 rows:\")\n",
    "print(X_scaled_df.head(10))\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"\\nStandardized Features Statistics (should be mean≈0, std≈1):\")\n",
    "print(X_scaled_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02623587",
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine optimal number of clusters\n",
    "k_range = range(2, 11)\n",
    "wcss = []\n",
    "silhouette_scores = []\n",
    "davies_bouldin_scores = []\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_scaled)\n",
    "    \n",
    "    wcss.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(X_scaled, kmeans.labels_))\n",
    "    davies_bouldin_scores.append(davies_bouldin_score(X_scaled, kmeans.labels_))\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    'k': list(k_range),\n",
    "    'WCSS': wcss,\n",
    "    'Silhouette Score': silhouette_scores,\n",
    "    'Davies-Bouldin Index': davies_bouldin_scores\n",
    "})\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4340d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#elbow plot\n",
    "axes[0].plot(k_range, wcss, 'bo-', linewidth=2, markersize=8)\n",
    "axes[0].set_xlabel('Number of Clusters (k)', fontsize=12)\n",
    "axes[0].set_ylabel('Within-Cluster Sum of Squares', fontsize=12)\n",
    "axes[0].set_title('Elbow Method', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "#silhouette score plot\n",
    "axes[1].plot(k_range, silhouette_scores, 'go-', linewidth=2, markersize=8)\n",
    "axes[1].set_xlabel('Number of Clusters (k)', fontsize=12)\n",
    "axes[1].set_ylabel('Silhouette Score', fontsize=12)\n",
    "axes[1].set_title('Silhouette Score (Higher is Better)', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "#davies-Bouldin Index plot\n",
    "axes[2].plot(k_range, davies_bouldin_scores, 'ro-', linewidth=2, markersize=8)\n",
    "axes[2].set_xlabel('Number of Clusters (k)', fontsize=12)\n",
    "axes[2].set_ylabel('Davies-Bouldin Index', fontsize=12)\n",
    "axes[2].set_title('Davies-Bouldin Index (Lower is Better)', fontsize=14, fontweight='bold')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#find optimal k\n",
    "optimal_k_silhouette = k_range[np.argmax(silhouette_scores)]\n",
    "optimal_k_db = k_range[np.argmin(davies_bouldin_scores)]\n",
    "\n",
    "print(f\"\\nOptimal k by Silhouette Score: {optimal_k_silhouette}\")\n",
    "print(f\"Optimal k by Davies-Bouldin Index: {optimal_k_db}\")\n",
    "print(f\"\\nSelected k: 4 (based on elbow method showing diminishing returns and good silhouette score)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6deef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform final clustering with optimal k\n",
    "optimal_k = 4\n",
    "kmeans_final = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "df['Cluster'] = kmeans_final.fit_predict(X_scaled)\n",
    "\n",
    "#add cluster labels to the original dataframe\n",
    "print(f\"Clustering completed with k={optimal_k}\")\n",
    "print(f\"\\nCluster distribution:\")\n",
    "print(df['Cluster'].value_counts().sort_index())\n",
    "print(f\"\\nPercentage distribution:\")\n",
    "print(df['Cluster'].value_counts(normalize=True).sort_index() * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b827f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate cluster centers (in original scale)\n",
    "cluster_centers = df.groupby('Cluster')[features_for_clustering].mean()\n",
    "print(\"Cluster Centers (Average Values):\")\n",
    "print(cluster_centers.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5cfedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#analyze cluster characteristics including categorical variables\n",
    "for cluster_id in range(optimal_k):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"CLUSTER {cluster_id} CHARACTERISTICS\")\n",
    "    \n",
    "    cluster_data = df[df['Cluster'] == cluster_id]\n",
    "    \n",
    "    #numerical statistics\n",
    "    print(f\"\\nSize: {len(cluster_data)} records ({len(cluster_data)/len(df)*100:.1f}%)\")\n",
    "    print(\"\\nNumerical Features (mean):\")\n",
    "    print(cluster_data[features_for_clustering].mean().round(2))\n",
    "    \n",
    "    #categorical distributions\n",
    "    print(\"\\nTop Product Types:\")\n",
    "    print(cluster_data['Product Type'].value_counts().head())\n",
    "    \n",
    "    print(\"\\nTop Products:\")\n",
    "    print(cluster_data['Product'].value_counts().head())\n",
    "    \n",
    "    print(\"\\nMarket Distribution:\")\n",
    "    print(cluster_data['Market'].value_counts())\n",
    "    \n",
    "    print(\"\\nMarket Size Distribution:\")\n",
    "    print(cluster_data['Market Size'].value_counts())\n",
    "    \n",
    "    print(\"\\nCaffeine Type Distribution:\")\n",
    "    print(cluster_data['Type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c06795",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA for 2D visualization\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "#creating a DataFrame for plotting\n",
    "pca_df = pd.DataFrame({\n",
    "    'PC1': X_pca[:, 0],\n",
    "    'PC2': X_pca[:, 1],\n",
    "    'Cluster': df['Cluster']\n",
    "})\n",
    "\n",
    "#plot clusters in PCA space\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = plt.scatter(pca_df['PC1'], pca_df['PC2'], c=pca_df['Cluster'], \n",
    "                     cmap='viridis', alpha=0.6, s=50, edgecolors='black', linewidth=0.5)\n",
    "plt.xlabel(f'Principal Component 1 ({pca.explained_variance_ratio_[0]:.2%} variance)', fontsize=12)\n",
    "plt.ylabel(f'Principal Component 2 ({pca.explained_variance_ratio_[1]:.2%} variance)', fontsize=12)\n",
    "plt.title('Cluster Visualization in PCA Space', fontsize=14, fontweight='bold')\n",
    "plt.colorbar(scatter, label='Cluster')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Total variance explained by 2 components: {pca.explained_variance_ratio_.sum():.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defe30d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#heatmap of standardized cluster centers\n",
    "cluster_centers_scaled = pd.DataFrame(\n",
    "    kmeans_final.cluster_centers_,\n",
    "    columns=features_for_clustering,\n",
    "    index=[f'Cluster {i}' for i in range(optimal_k)]\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(cluster_centers_scaled, annot=True, fmt='.2f', cmap='RdYlGn', \n",
    "            center=0, linewidths=1, cbar_kws={'label': 'Standardized Value'})\n",
    "plt.title('Cluster Centers (Standardized Features)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Features', fontsize=12)\n",
    "plt.ylabel('Clusters', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88500102",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "summary_table = df.groupby('Cluster').agg({\n",
    "    'Sales': ['mean', 'std', 'min', 'max'],\n",
    "    'Profit': ['mean', 'std', 'min', 'max'],\n",
    "    'Margin': ['mean', 'std'],\n",
    "    'Marketing': ['mean', 'std'],\n",
    "    'Inventory': ['mean', 'std'],\n",
    "    'Difference Between Actual and Target Profit': ['mean', 'std']\n",
    "}).round(2)\n",
    "print(summary_table)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
